{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharafinajwa/Face-Tone-Classification/blob/main/Tone_Wajah.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5b63P0_q2Ai"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLU37JTfr14P"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Upload file .zip dari komputer\n",
        "uploaded = files.upload()\n",
        "zip_filename = list(uploaded.keys())[0]\n",
        "print(f\"File yang diupload: {zip_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfwIPx0zsnQU"
      },
      "outputs": [],
      "source": [
        "extract_dir = './dataset_skintone'\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Cek struktur direktori\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    level = root.replace(extract_dir, \"\").count(os.sep)\n",
        "    indent = \" \" * 4 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    for f in files[:3]:\n",
        "        print(f\"{indent}    {f}\")\n",
        "\n",
        "print(f\"✅ Ekstrak selesai di: {extract_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1YB9PaCpe_-"
      },
      "outputs": [],
      "source": [
        "# Menampilkan jumlah gambar per kelas\n",
        "train_dir = extract_dir  # Corrected path\n",
        "class_names = os.listdir(train_dir)\n",
        "class_counts = {}\n",
        "\n",
        "print(\"\\nJumlah gambar per kelas:\")\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "    # Check if it's a directory before listing files\n",
        "    if os.path.isdir(class_dir):\n",
        "        count = len(os.listdir(class_dir))\n",
        "        class_counts[class_name] = count\n",
        "        print(f\"- {class_name}: {count}\")\n",
        "\n",
        "# Opsional: Menampilkan contoh gambar dari setiap kelas\n",
        "print(\"\\nContoh gambar dari setiap kelas:\")\n",
        "plt.figure(figsize=(10, 10))\n",
        "# Only iterate through actual class directories\n",
        "for i, class_name in enumerate([d for d in class_names if os.path.isdir(os.path.join(train_dir, d))]):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "    sample_image_name = os.listdir(class_dir)[0] # Ambil gambar pertama\n",
        "    sample_image_path = os.path.join(class_dir, sample_image_name)\n",
        "\n",
        "    img = load_img(sample_image_path)\n",
        "    plt.subplot(1, len([d for d in class_names if os.path.isdir(os.path.join(train_dir, d))]), i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(class_name)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IW1qGUPPssRr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    extract_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_data = datagen.flow_from_directory(\n",
        "    extract_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Menampilkan jumlah gambar di setiap set\n",
        "print(f\"Jumlah gambar training: {train_data.samples}\")\n",
        "print(f\"Jumlah gambar validation: {val_data.samples}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HRXZg4Vs-ql"
      },
      "outputs": [],
      "source": [
        "# Menambahkan augmentasi: rotasi, flipping (horizontal), dan zoom\n",
        "datagen_augmented = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,        # Rentang rotasi (dalam derajat)\n",
        "    horizontal_flip=True,     # Mengaktifkan flipping horizontal\n",
        "    zoom_range=0.2,           # Rentang zoom\n",
        "    validation_split=0.2      # Tetap menggunakan validasi split\n",
        ")\n",
        "\n",
        "# Membuat generator data untuk training dengan augmentasi\n",
        "train_data_augmented = datagen_augmented.flow_from_directory(\n",
        "    extract_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Generator data untuk validasi tanpa augmentasi (hanya rescaling)\n",
        "val_data_augmented = ImageDataGenerator(rescale=1./255, validation_split=0.2).flow_from_directory(\n",
        "    extract_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Cek contoh batch dari generator yang diaugmentasi\n",
        "print(\"\\nContoh batch setelah augmentasi:\")\n",
        "img_batch_aug, label_batch_aug = next(iter(train_data_augmented))\n",
        "print(f\"Gambar (augmented): {img_batch_aug.shape}\")\n",
        "print(f\"Label (augmented): {label_batch_aug.shape}\")\n",
        "\n",
        "# Menampilkan beberapa contoh gambar yang diaugmentasi (opsional)\n",
        "print(\"\\nMenampilkan beberapa contoh gambar yang diaugmentasi:\")\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9): # Tampilkan 9 gambar\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(img_batch_aug[i])\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgmU-Xcrf6fh"
      },
      "outputs": [],
      "source": [
        "# prompt: contoh gambar sebelum augmentasi dan sesudah\n",
        "\n",
        "# Ambil satu contoh gambar dari dataset sebelum augmentasi\n",
        "class_example = [d for d in class_names if os.path.isdir(os.path.join(train_dir, d))][0] # Ambil kelas pertama\n",
        "sample_image_path = os.path.join(train_dir, class_example, os.listdir(os.path.join(train_dir, class_example))[0]) # Ambil gambar pertama dari kelas pertama\n",
        "\n",
        "original_img = load_img(sample_image_path, target_size=(128, 128))\n",
        "original_img_array = img_to_array(original_img)\n",
        "# Tambahkan dimensi batch karena flow memerlukan input 4D\n",
        "original_img_array = np.expand_dims(original_img_array, axis=0)\n",
        "\n",
        "# Menampilkan gambar asli\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(original_img)\n",
        "plt.title(\"Gambar Asli (Sebelum Augmentasi)\")\n",
        "plt.axis('off')\n",
        "\n",
        "# Menghasilkan beberapa contoh gambar yang diaugmentasi dari gambar asli\n",
        "augmented_images = []\n",
        "# Gunakan generator augmentasi yang sudah dibuat\n",
        "for _ in range(1): # Hanya butuh 1 contoh gambar setelah augmentasi\n",
        "    for batch in datagen_augmented.flow(original_img_array, batch_size=1):\n",
        "        augmented_images.append(batch[0])\n",
        "        break # Keluar setelah mendapatkan 1 gambar\n",
        "\n",
        "# Menampilkan contoh gambar setelah augmentasi\n",
        "plt.subplot(1, 2, 2)\n",
        "# img_to_array mengembalikan float, imshow memerlukan nilai antara 0-1 atau 0-255\n",
        "# Generator dengan rescale sudah menghasilkan nilai 0-1\n",
        "plt.imshow(augmented_images[0])\n",
        "plt.title(\"Gambar Setelah Augmentasi\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbgyfCsSsvUu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a8GSuXYeLzm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2h4SqUkOsy2v"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Definisikan EarlyStopping callback\n",
        "# pantau val_loss dan hentikan pelatihan jika tidak ada perbaikan selama 5 epoch\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    train_data_augmented,\n",
        "    validation_data=val_data_augmented,\n",
        "    epochs=20, # Jumlah epoch bisa lebih besar karena ada early stopping\n",
        "    callbacks=[early_stopping] # Tambahkan callback early stopping\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMyBKIjJ0kvY"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(val_data)\n",
        "print(f\"Akurasi Model: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6Fi7sx6x5GD"
      },
      "outputs": [],
      "source": [
        "  from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get true labels and predictions for the validation data\n",
        "val_labels = []\n",
        "val_preds = []\n",
        "val_data.reset() # Reset generator to start from the beginning\n",
        "\n",
        "# Iterate through the validation data generator to get all labels and predictions\n",
        "for _ in range(len(val_data)):\n",
        "    imgs, labels = next(val_data)\n",
        "    val_labels.extend(np.argmax(labels, axis=1))\n",
        "    predictions = model.predict(imgs)\n",
        "    val_preds.extend(np.argmax(predictions, axis=1))\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(val_labels, val_preds)\n",
        "\n",
        "# Get class names from the validation generator\n",
        "class_names = list(val_data.class_indices.keys())\n",
        "\n",
        "# Display the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Generate and print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(val_labels, val_preds, target_names=class_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JkbVjl74WOmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVdz7DEKdXdJ"
      },
      "outputs": [],
      "source": [
        "# Menampilkan grafik training and validation (accuracy and loss)\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 1) # 1 row, 2 columns, 1st plot\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim([0, 1]) # Set y-axis limit from 0 to 1 for accuracy\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 2) # 1 row, 2 columns, 2nd plot\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.tight_layout() # Adjust layout to prevent overlap\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "# Upload gambar untuk diuji\n",
        "uploaded = files.upload()\n",
        "img_path = list(uploaded.keys())[0]\n",
        "\n",
        "img = load_img(img_path, target_size=(128,128))\n",
        "img_array = img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "pred = model.predict(img_array)\n",
        "class_names = list(train_data.class_indices.keys())\n",
        "print(f\"Gambar ini diklasifikasi sebagai: {class_names[np.argmax(pred)]}\")\n"
      ],
      "metadata": {
        "id": "umgL7js0Phe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANl0urxI024N"
      },
      "outputs": [],
      "source": [
        "model.save(\"cnn_skintone_model.h5\")\n",
        "print(\"✅ Model berhasil disimpan.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOclBV7l1DkyAd8YZnDXeg0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}